{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Lab 3\n",
        "1. Ensemble methods\n",
        "    - Bagging\n",
        "    - Boosting\n",
        "    - Random Forests\n",
        "2. Hyperparameter Tuning\n",
        "3. Final System"
      ],
      "metadata": {
        "id": "OW7FhavoOT6Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "9TYMTIKOF9R2"
      },
      "outputs": [],
      "source": [
        "from random import seed\n",
        "from random import randrange\n",
        "from math import sqrt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "from sklearn.base import clone\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"output.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "9JmMh4TQO6F0",
        "outputId": "e572e6aa-598f-412b-e92a-67568850ecbb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   systolic  eyesight(left)  hearing(right)  ...       Gtp  serum creatinine^2     Gtp^2\n",
              "0  0.981702       -1.257856               1  ... -0.295342            0.357517  0.087227\n",
              "1  1.845852       -1.009169               2  ...  0.025124            1.335205  0.000631\n",
              "2 -0.353802       -1.506543               1  ...  0.537870            0.267536  0.289304\n",
              "3  0.667465        1.229017               1  ... -0.199202            0.357517  0.039681\n",
              "4 -0.118125        1.229017               1  ... -0.615808            0.267536  0.379219\n",
              "\n",
              "[5 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2aa85b3-6574-4b57-9522-1ad3310278c3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>systolic</th>\n",
              "      <th>eyesight(left)</th>\n",
              "      <th>hearing(right)</th>\n",
              "      <th>ALT</th>\n",
              "      <th>relaxation</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>AST</th>\n",
              "      <th>hearing(left)</th>\n",
              "      <th>smoking</th>\n",
              "      <th>serum creatinine</th>\n",
              "      <th>Gtp</th>\n",
              "      <th>serum creatinine^2</th>\n",
              "      <th>Gtp^2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.981702</td>\n",
              "      <td>-1.257856</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.087326</td>\n",
              "      <td>1.125777</td>\n",
              "      <td>-0.837985</td>\n",
              "      <td>-0.371570</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.597927</td>\n",
              "      <td>-0.295342</td>\n",
              "      <td>0.357517</td>\n",
              "      <td>0.087227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.845852</td>\n",
              "      <td>-1.009169</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.199983</td>\n",
              "      <td>0.681066</td>\n",
              "      <td>-0.063252</td>\n",
              "      <td>0.156700</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.155511</td>\n",
              "      <td>0.025124</td>\n",
              "      <td>1.335205</td>\n",
              "      <td>0.000631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.353802</td>\n",
              "      <td>-1.506543</td>\n",
              "      <td>1</td>\n",
              "      <td>0.250645</td>\n",
              "      <td>-0.208355</td>\n",
              "      <td>-0.626695</td>\n",
              "      <td>0.156700</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.517239</td>\n",
              "      <td>0.537870</td>\n",
              "      <td>0.267536</td>\n",
              "      <td>0.289304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.667465</td>\n",
              "      <td>1.229017</td>\n",
              "      <td>1</td>\n",
              "      <td>0.025331</td>\n",
              "      <td>1.236955</td>\n",
              "      <td>-0.556264</td>\n",
              "      <td>-0.582878</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.597927</td>\n",
              "      <td>-0.199202</td>\n",
              "      <td>0.357517</td>\n",
              "      <td>0.039681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.118125</td>\n",
              "      <td>1.229017</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.763267</td>\n",
              "      <td>-0.097177</td>\n",
              "      <td>-1.436643</td>\n",
              "      <td>-0.688532</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.517239</td>\n",
              "      <td>-0.615808</td>\n",
              "      <td>0.267536</td>\n",
              "      <td>0.379219</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2aa85b3-6574-4b57-9522-1ad3310278c3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f2aa85b3-6574-4b57-9522-1ad3310278c3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f2aa85b3-6574-4b57-9522-1ad3310278c3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-edce5694-fadb-4e21-a154-b4ecc600d2cc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-edce5694-fadb-4e21-a154-b4ecc600d2cc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-edce5694-fadb-4e21-a154-b4ecc600d2cc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('smoking', axis=1)\n",
        "y = df['smoking']"
      ],
      "metadata": {
        "id": "K6WzrET4S4xm"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbUVQb2STC4Z",
        "outputId": "af5af86a-3c5d-4c65-93cc-ab7dc0cdc9a0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(127404, 12)\n",
            "(31852, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Bagging (Bootstrap Aggregating)**"
      ],
      "metadata": {
        "id": "RwZVToeeOx0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resources: [Bagging](https://insidelearningmachines.com/build-a-bagging-classifier-in-python/)"
      ],
      "metadata": {
        "id": "9EM_FlMZFYcc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bootstrapping is a statistical method to create sample data without leaving the properties of the actual dataset. The individual samples of data called bootstrap samples."
      ],
      "metadata": {
        "id": "LG8ZDwN_o-Os"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps:\n",
        "\n",
        "1. Produce N bootstrap samples on the training data\n",
        "2. Loop through each of the i = 1 -> N bootstrap samples:\n",
        "  - Fit a model to sample i\n",
        "  - Produce the desired predictions with this model.\n",
        "  - Repeat the above two steps, storing the trained models and predictions\n",
        "4. Aggregate the predictions. In the event of having a labelled test set, compare these results with the test dataset labels\n",
        "5. If the results are good, we can deploy our trained ensemble. Input data is provided to the ensemble, and each constituent model produces predictions. These predictions are aggregated to yield a final result."
      ],
      "metadata": {
        "id": "jGQkJZpAp3ph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter"
      ],
      "metadata": {
        "id": "MwBXYiDGu0TH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_estimators = 10  # Number of bagging iterations"
      ],
      "metadata": {
        "id": "JoUBDCOeu4X_"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Bagging():\n",
        "    '''Bagging Classifier from Scratch.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_estimators : int\n",
        "        number of bagging iterations\n",
        "    '''\n",
        "\n",
        "    def __init__(self, n_estimators):\n",
        "        self.n_elements = n_estimators\n",
        "        self.models = []\n",
        "\n",
        "    # Private function to make bootstrap samples\n",
        "    def __make_bootstraps(self, data):\n",
        "        # Initialize output dictionary & unique value count\n",
        "        dc = {}\n",
        "        unip = 0\n",
        "        # Get sample size\n",
        "        b_size = data.shape[0]\n",
        "        # Get list of row indexes\n",
        "        idx = [i for i in range(b_size)]\n",
        "        # Loop through the required number of bootstraps\n",
        "        for b in range(self.n_elements):\n",
        "            # Obtain bootstrap samples with replacement\n",
        "            sidx = np.random.choice(idx, replace=True, size=b_size)\n",
        "            b_samp = data[sidx, :]\n",
        "            # Compute number of unique values contained in the bootstrap sample\n",
        "            unip += len(set(sidx))\n",
        "            # Obtain out-of-bag samples for the current bootstrap\n",
        "            oidx = list(set(idx) - set(sidx))\n",
        "            o_samp = np.array([])\n",
        "            if oidx:\n",
        "                o_samp = data[oidx, :]\n",
        "            # Store results\n",
        "            dc['boot_' + str(b)] = {'boot': b_samp, 'test': o_samp}\n",
        "        # Return the bootstrap results\n",
        "        return dc\n",
        "\n",
        "    # Train the ensemble\n",
        "    def fit(self, X_train, y_train, print_metrics=False):\n",
        "      # Convert y_train to a NumPy array\n",
        "      training_data = np.concatenate((X_train, np.array(y_train).reshape(-1, 1)), axis=1)\n",
        "      # Make bootstrap samples\n",
        "      dcBoot = self.__make_bootstraps(training_data)\n",
        "      # Initialize metric arrays\n",
        "      accs = np.array([])\n",
        "      pres = np.array([])\n",
        "      recs = np.array([])\n",
        "      # Iterate through each bootstrap sample & fit a model\n",
        "      cls = DecisionTreeClassifier(class_weight='balanced')\n",
        "      for b in dcBoot:\n",
        "          # Make a clone of the model\n",
        "          model = clone(cls)\n",
        "          # Fit a decision tree classifier to the current sample\n",
        "          model.fit(dcBoot[b]['boot'][:, :-1], dcBoot[b]['boot'][:, -1].reshape(-1, 1))\n",
        "          # Append the fitted model\n",
        "          self.models.append(model)\n",
        "          # Compute the predictions on the out-of-bag test set & compute metrics\n",
        "          if dcBoot[b]['test'].size:\n",
        "              yp = model.predict(dcBoot[b]['test'][:, :-1])\n",
        "              acc = accuracy_score(dcBoot[b]['test'][:, -1], yp)\n",
        "              pre = precision_score(dcBoot[b]['test'][:, -1], yp)\n",
        "              rec = recall_score(dcBoot[b]['test'][:, -1], yp)\n",
        "              # Store the error metrics\n",
        "              accs = np.concatenate((accs, [acc]))\n",
        "              pres = np.concatenate((pres, [pre]))\n",
        "              recs = np.concatenate((recs, [rec]))\n",
        "\n",
        "    # Predict from the ensemble\n",
        "    def predict(self, X):\n",
        "        # Check we've fit the ensemble\n",
        "        if not self.models:\n",
        "            print('You must train the ensemble before making predictions!')\n",
        "            return None\n",
        "        # Loop through each fitted model\n",
        "        predictions = []\n",
        "        for m in self.models:\n",
        "            # Make predictions on the input X\n",
        "            yp = m.predict(X)\n",
        "            # Append predictions to storage list\n",
        "            predictions.append(yp.reshape(-1, 1))\n",
        "        # Compute the ensemble prediction\n",
        "        ypred = np.round(np.mean(np.concatenate(predictions, axis=1), axis=1)).astype(int)\n",
        "        # Return the prediction\n",
        "        return ypred"
      ],
      "metadata": {
        "id": "TKl9Jh-wnRtQ"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "rwSCuUc7CJZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert X_train and X_test to NumPy arrays\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "# Train the Bagging model\n",
        "bagging = Bagging(n_estimators=10)\n",
        "bagging.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = bagging.predict(X_test)\n",
        "\n",
        "# Compute accuracy, precision, and recall\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the results\n",
        "print(f\"Bagging Accuracy: {(accuracy*100):.4f}%\")\n",
        "print(f\"Bagging Precision: {(precision*100):.4f}%\")\n",
        "print(f\"Bagging Recall: {(recall*100):.4f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsBg7XsqsdOZ",
        "outputId": "2165812f-4ea0-4b88-c8eb-96805e528373"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Accuracy: 68.1998%\n",
            "Bagging Precision: 68.0057%\n",
            "Bagging Recall: 68.1998%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Boosting**"
      ],
      "metadata": {
        "id": "pXQhQEpsOLqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resources: [Boosting](https://randomrealizations.com/posts/gradient-boosting-multi-class-classification-from-scratch/)"
      ],
      "metadata": {
        "id": "f9BntPcKPIYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters"
      ],
      "metadata": {
        "id": "w62MzE1-TK2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_estimators = 10  # Number of boosting iterations\n",
        "alpha = 0.01  # learning rate\n",
        "max_depth = 3 # maximum tree depth"
      ],
      "metadata": {
        "id": "mRj1WBl3TKEs"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Boosting():\n",
        "    '''Gradient Boosting Classifier from Scratch.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_estimators : int\n",
        "        number of boosting iterations\n",
        "\n",
        "    learning_rate : float\n",
        "        learning rate hyperparameter\n",
        "\n",
        "    max_depth : int\n",
        "        maximum tree depth\n",
        "    '''\n",
        "\n",
        "    def __init__(self, n_estimators, learning_rate, max_depth):\n",
        "        self.n_estimators=n_estimators;\n",
        "        self.learning_rate=learning_rate\n",
        "        self.max_depth=max_depth;\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        '''Fit the GBM\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : ndarray of size (number observations, number features)\n",
        "            design matrix\n",
        "\n",
        "        y : ndarray of size (number observations,)\n",
        "            integer-encoded target labels in {0,1,...,k-1}\n",
        "        '''\n",
        "\n",
        "        self.n_classes = pd.Series(y).nunique()\n",
        "        y_ohe = self._one_hot_encode_labels(y)\n",
        "\n",
        "        raw_predictions = np.zeros(shape=y_ohe.shape)\n",
        "        probabilities = self._softmax(raw_predictions)\n",
        "        self.boosters = []\n",
        "        for m in range(self.n_estimators):\n",
        "            class_trees = []\n",
        "            for k in range(self.n_classes):\n",
        "                negative_gradients = self._negative_gradients(y_ohe[:, k], probabilities[:, k])\n",
        "                hessians = self._hessians(probabilities[:, k])\n",
        "                tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
        "                tree.fit(X, negative_gradients);\n",
        "                self._update_terminal_nodes(tree, X, negative_gradients, hessians)\n",
        "                raw_predictions[:, k] += self.learning_rate * tree.predict(X)\n",
        "                probabilities = self._softmax(raw_predictions)\n",
        "                class_trees.append(tree)\n",
        "            self.boosters.append(class_trees)\n",
        "\n",
        "    def _one_hot_encode_labels(self, y):\n",
        "        if isinstance(y, pd.Series): y = y.values\n",
        "        ohe = OneHotEncoder()\n",
        "        y_ohe = ohe.fit_transform(y.reshape(-1, 1)).toarray()\n",
        "        return y_ohe\n",
        "\n",
        "    def _negative_gradients(self, y_ohe, probabilities):\n",
        "        return y_ohe - probabilities\n",
        "\n",
        "    def _hessians(self, probabilities):\n",
        "        return probabilities * (1 - probabilities)\n",
        "\n",
        "    def _softmax(self, raw_predictions):\n",
        "        numerator = np.exp(raw_predictions)\n",
        "        denominator = np.sum(np.exp(raw_predictions), axis=1).reshape(-1, 1)\n",
        "        return numerator / denominator\n",
        "\n",
        "    def _update_terminal_nodes(self, tree, X, negative_gradients, hessians):\n",
        "        '''Update the terminal node predicted values'''\n",
        "        # terminal node id's\n",
        "        leaf_nodes = np.nonzero(tree.tree_.children_left == -1)[0]\n",
        "        # compute leaf for each sample in ``X``.\n",
        "        leaf_node_for_each_sample = tree.apply(X)\n",
        "        for leaf in leaf_nodes:\n",
        "            samples_in_this_leaf = np.where(leaf_node_for_each_sample == leaf)[0]\n",
        "            negative_gradients_in_leaf = negative_gradients.take(samples_in_this_leaf, axis=0)\n",
        "            hessians_in_leaf = hessians.take(samples_in_this_leaf, axis=0)\n",
        "            val = np.sum(negative_gradients_in_leaf) / np.sum(hessians_in_leaf)\n",
        "            tree.tree_.value[leaf, 0, 0] = val\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        '''Generate probability predictions for the given input data.'''\n",
        "        raw_predictions =  np.zeros(shape=(X.shape[0], self.n_classes))\n",
        "        for k in range(self.n_classes):\n",
        "            for booster in self.boosters:\n",
        "                raw_predictions[:, k] +=self.learning_rate * booster[k].predict(X)\n",
        "        probabilities = self._softmax(raw_predictions)\n",
        "        return probabilities\n",
        "\n",
        "    def predict(self, X):\n",
        "        '''Generate predicted labels (as 1-d array)'''\n",
        "        probabilities = self.predict_proba(X)\n",
        "        return np.argmax(probabilities, axis=1)"
      ],
      "metadata": {
        "id": "w-BobGo1eT1Z"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "0PM2fmSuepTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boosting = Boosting(n_estimators, alpha, max_depth)\n",
        "boosting.fit(X_train, y_train)\n",
        "y_pred = boosting.predict(X_test)\n",
        "\n",
        "# Compute accuracy, precision, and recall on the test set\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the results\n",
        "print(f\"Boosting Accuracy: {(accuracy*100):.4f}%\")\n",
        "print(f\"Boosting Precision: {(precision*100):.4f}%\")\n",
        "print(f\"Boosting Recall: {(recall*100):.4f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rL9au1oeonx",
        "outputId": "4b7b00df-58dc-43ad-f1b2-1c067cd224b9"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Boosting Accuracy: 69.8010%\n",
            "Boosting Precision: 69.7791%\n",
            "Boosting Recall: 69.8010%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Random Forests**"
      ],
      "metadata": {
        "id": "U8-zh3U4iQeK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resources: [Random Forest](https://insidelearningmachines.com/build-a-random-forest-in-python/)"
      ],
      "metadata": {
        "id": "oHXP19BPipE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_trees = 10 # Number of trees in the forest\n",
        "max_depth = 3 # Maximum depth of the tree\n",
        "min_samples_split = 2 # The minimum number of samples required to split an internal node"
      ],
      "metadata": {
        "id": "PcaBeo_8Hu0g"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomForest():\n",
        "    from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "class RandomForest():\n",
        "    def __init__(self, n_trees, max_depth, min_samples_split, criterion='gini', balance_class_weights=False):\n",
        "        self.n_trees = n_trees\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.criterion = criterion  # Update the parameter name to 'criterion'\n",
        "        self.balance_class_weights = balance_class_weights\n",
        "        self.trees = []\n",
        "\n",
        "    # protected function to obtain the right decision tree\n",
        "    def _make_tree_model(self):\n",
        "        return DecisionTreeClassifier(max_depth=self.max_depth, min_samples_split=self.min_samples_split, criterion=self.criterion, class_weight='balanced' if self.balance_class_weights else None)\n",
        "\n",
        "    # private function to make bootstrap samples\n",
        "    def __make_bootstraps(self,data):\n",
        "        # initialize output dictionary & unique value count\n",
        "        dc = {}\n",
        "        unip = 0\n",
        "        # get sample size\n",
        "        b_size = data.shape[0]\n",
        "        # get list of row indexes\n",
        "        idx = [i for i in range(b_size)]\n",
        "        # loop through the required number of bootstraps\n",
        "        for b in range(self.n_trees):\n",
        "            # obtain boostrap samples with replacement\n",
        "            sidx = np.random.choice(idx,replace=True,size=b_size)\n",
        "            b_samp = data[sidx,:]\n",
        "            #compute number of unique values contained in the bootstrap sample\n",
        "            unip += len(set(sidx))\n",
        "            # obtain out-of-bag samples for the current b\n",
        "            oidx = list(set(idx) - set(sidx))\n",
        "            o_samp = np.array([])\n",
        "            if oidx:\n",
        "                o_samp = data[oidx,:]\n",
        "            #store results\n",
        "            dc['boot_'+str(b)] = {'boot':b_samp,'test':o_samp}\n",
        "        #return the bootstrap results\n",
        "        return(dc)\n",
        "\n",
        "    # protected function to train the ensemble\n",
        "    def _train(self,X_train,y_train):\n",
        "        #package the input data\n",
        "        training_data = np.concatenate((X_train,y_train.reshape(-1,1)),axis=1)\n",
        "        #make bootstrap samples\n",
        "        dcBoot = self.__make_bootstraps(training_data)\n",
        "        #iterate through each bootstrap sample & fit a model ##\n",
        "        tree_m = self._make_tree_model()\n",
        "        dcOob = {}\n",
        "        for b in dcBoot:\n",
        "            # make a clone of the model\n",
        "            model = clone(tree_m)\n",
        "            # fit a decision tree model to the current sample\n",
        "            model.fit(dcBoot[b]['boot'][:,:-1],dcBoot[b]['boot'][:,-1].reshape(-1, 1))\n",
        "            # append the fitted model\n",
        "            self.trees.append(model)\n",
        "            # store the out-of-bag test set for the current bootstrap\n",
        "            if dcBoot[b]['test'].size:\n",
        "                dcOob[b] = dcBoot[b]['test']\n",
        "            else:\n",
        "                dcOob[b] = np.array([])\n",
        "        #return the oob data set\n",
        "        return(dcOob)\n",
        "\n",
        "    # train the ensemble\n",
        "    def fit(self, X_train, y_train,print_metrics=False):\n",
        "        # call the protected training method\n",
        "        dcOob = self._train(X_train,y_train)\n",
        "        # if selected, compute the standard errors and print them\n",
        "        if print_metrics:\n",
        "            # initialise metric arrays\n",
        "            accs = np.array([])\n",
        "            pres = np.array([])\n",
        "            recs = np.array([])\n",
        "            # loop through each bootstrap sample\n",
        "            for b,m in zip(dcOob,self.trees):\n",
        "                # compute the predictions on the out-of-bag test set & compute metrics\n",
        "                if dcOob[b].size:\n",
        "                    yp  = m.predict(dcOob[b][:,:-1])\n",
        "                    acc = accuracy_score(dcOob[b][:,-1],yp)\n",
        "                    pre = precision_score(dcOob[b][:,-1],yp,average='weighted')\n",
        "                    rec = recall_score(dcOob[b][:,-1],yp,average='weighted')\n",
        "\n",
        "    #protected function to predict from the ensemble\n",
        "    def _predict(self,X):\n",
        "        #check we've fit the ensemble\n",
        "        if not self.trees:\n",
        "            print('You must train the ensemble before making predictions!')\n",
        "            return(None)\n",
        "        #loop through each fitted model\n",
        "        predictions = []\n",
        "        for m in self.trees:\n",
        "            #make predictions on the input X\n",
        "            yp = m.predict(X)\n",
        "            #append predictions to storage list\n",
        "            predictions.append(yp.reshape(-1,1))\n",
        "        #compute the ensemble prediction\n",
        "        ypred = np.mean(np.concatenate(predictions,axis=1),axis=1)\n",
        "        #return the prediction\n",
        "        return(ypred)\n",
        "\n",
        "    # predict from the ensemble\n",
        "    def predict(self,X):\n",
        "        # call the protected prediction method\n",
        "        ypred = self._predict(X)\n",
        "        # convert the results into integer values & return\n",
        "        return(np.round(ypred).astype(int))"
      ],
      "metadata": {
        "id": "Wqr5dpNRiZvR"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "OoPL557KHXka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert X_train and X_test to NumPy arrays\n",
        "# X_train = np.array(X_train)\n",
        "# X_test = np.array(X_test)\n",
        "y_train = np.array(y_train).reshape(-1, 1)\n",
        "y_test = np.array(y_test).reshape(-1, 1)\n",
        "\n",
        "random_forest = RandomForest(n_trees ,max_depth, min_samples_split)\n",
        "random_forest.fit(X_train, y_train)\n",
        "y_pred = random_forest.predict(X_test)\n",
        "\n",
        "# Compute accuracy, precision, and recall on the test set\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print results\n",
        "print(f\"Random Forest Accuracy: {(accuracy*100):.4f}%\")\n",
        "print(f\"Random Forest Precision: {(precision*100):.4f}%\")\n",
        "print(f\"Random Forest Recall: {(recall*100):.4f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RY6_QQXOHZHa",
        "outputId": "0e20db14-dfeb-4575-bc0d-5142a0e725a3"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 69.8010%\n",
            "Random Forest Precision: 69.7791%\n",
            "Random Forest Recall: 69.8010%\n"
          ]
        }
      ]
    }
  ]
}